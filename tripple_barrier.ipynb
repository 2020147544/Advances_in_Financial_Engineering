{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import and Settings\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
    "from collections import deque\n",
    "from itertools import accumulate\n",
    "from cprint import *\n",
    "import bisect\n",
    "import warnings\n",
    "\n",
    "plt.rcParams['figure.figsize'] = 17,9\n",
    "sns.set_style('whitegrid')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. 데이터\n",
    "kq150_data = pd.read_csv(r'C:\\Users\\John\\OneDrive\\바탕 화면\\퀀트관련\\퀀트스터디\\afml Project\\Advances_in_Financial_Engineering-main\\KQ150.csv',index_col=0)\n",
    "kq150_dollar = pd.read_csv(r'C:\\Users\\John\\OneDrive\\바탕 화면\\퀀트관련\\퀀트스터디\\afml Project\\Advances_in_Financial_Engineering-main\\Kp200F_volume_bars_500.csv',index_col=0)\n",
    "kq150_data.index = pd.to_datetime(kq150_data.index)\n",
    "#kq150_dollar.index = pd.to_datetime(kq150_dollar.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date-Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-04 10:00:00</th>\n",
       "      <td>1090.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1090.0</td>\n",
       "      <td>1092.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 10:01:00</th>\n",
       "      <td>1092.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 10:02:00</th>\n",
       "      <td>1093.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 10:03:00</th>\n",
       "      <td>1093.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1093.0</td>\n",
       "      <td>1093.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04 10:04:00</th>\n",
       "      <td>1092.7</td>\n",
       "      <td>1092.7</td>\n",
       "      <td>1092.5</td>\n",
       "      <td>1092.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25 15:31:00</th>\n",
       "      <td>1250.4</td>\n",
       "      <td>1251.2</td>\n",
       "      <td>1250.4</td>\n",
       "      <td>1250.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25 15:32:00</th>\n",
       "      <td>1250.5</td>\n",
       "      <td>1251.7</td>\n",
       "      <td>1250.2</td>\n",
       "      <td>1251.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25 15:33:00</th>\n",
       "      <td>1251.4</td>\n",
       "      <td>1251.9</td>\n",
       "      <td>1250.9</td>\n",
       "      <td>1251.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25 15:34:00</th>\n",
       "      <td>1251.5</td>\n",
       "      <td>1251.7</td>\n",
       "      <td>1249.8</td>\n",
       "      <td>1250.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-04-25 15:45:00</th>\n",
       "      <td>1245.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>1245.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>654558 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Open    High     Low   Close\n",
       "Date-Time                                          \n",
       "2016-01-04 10:00:00  1090.0  1092.0  1090.0  1092.0\n",
       "2016-01-04 10:01:00  1092.0  1093.0  1092.0  1093.0\n",
       "2016-01-04 10:02:00  1093.0  1093.0  1093.0  1093.0\n",
       "2016-01-04 10:03:00  1093.0  1093.0  1093.0  1093.0\n",
       "2016-01-04 10:04:00  1092.7  1092.7  1092.5  1092.5\n",
       "...                     ...     ...     ...     ...\n",
       "2023-04-25 15:31:00  1250.4  1251.2  1250.4  1250.6\n",
       "2023-04-25 15:32:00  1250.5  1251.7  1250.2  1251.4\n",
       "2023-04-25 15:33:00  1251.4  1251.9  1250.9  1251.5\n",
       "2023-04-25 15:34:00  1251.5  1251.7  1249.8  1250.1\n",
       "2023-04-25 15:45:00  1245.0  1245.0  1245.0  1245.0\n",
       "\n",
       "[654558 rows x 4 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kq150_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = kq150_data.iloc[:2000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 파킨슨 변동성\n",
    "def parkinson_volatility(df, n):\n",
    "    data_scope = deque()\n",
    "    date = df.index\n",
    "    parkinson_vol_lst = []\n",
    "    for i in range(len(df)):\n",
    "        data_scope.append(df.iloc[i, :])\n",
    "        if len(data_scope) > n:\n",
    "            data_scope.popleft()\n",
    "\n",
    "        parkinson_vol = np.sqrt(\n",
    "            sum(np.log(pd.DataFrame(data_scope)['High'].values / pd.DataFrame(data_scope)['Low'].values) ** 2) / (\n",
    "                        4 * np.log(2) * n))\n",
    "        parkinson_vol_lst.append(parkinson_vol)\n",
    "    \n",
    "    parkinson_vol_df = pd.DataFrame(data=parkinson_vol_lst, index=date, columns=['parksinson_vol'])\n",
    "    return parkinson_vol_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDailyVol(close,span0=100):\n",
    "    '''\n",
    "    daily vol, reindexed to close\n",
    "    - used to set default profit taking and stop-loss limits\n",
    "    '''\n",
    "    df0=close.index.searchsorted(close.index-pd.Timedelta(days=1))\n",
    "    df0=df0[df0>0]\n",
    "    df0=pd.Series(close.index[df0-1], index=close.index[close.shape[0]-df0.shape[0]:])\n",
    "    df0=close.loc[df0.index]/close.loc[df0.values].values-1 # daily returns\n",
    "    df0=df0.ewm(span=span0).std()\n",
    "    return df0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                     parksinson_vol\n",
       " Date-Time                          \n",
       " 2016-01-04 10:00:00        0.000348\n",
       " 2016-01-04 10:01:00        0.000389\n",
       " 2016-01-04 10:02:00        0.000389\n",
       " 2016-01-04 10:03:00        0.000389\n",
       " 2016-01-04 10:04:00        0.000391\n",
       " ...                             ...\n",
       " 2016-01-13 10:23:00        0.000191\n",
       " 2016-01-13 10:24:00        0.000222\n",
       " 2016-01-13 10:25:00        0.000248\n",
       " 2016-01-13 10:26:00        0.000294\n",
       " 2016-01-13 10:27:00        0.000285\n",
       " \n",
       " [2000 rows x 1 columns],\n",
       " parksinson_vol    0.000382\n",
       " dtype: float64)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parkinson_vol = parkinson_volatility(test_data,10)\n",
    "parkinson_vol, parkinson_vol.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. CS_filter\n",
    "def getTEvents(gRaw,h): #gRaw: dollar['Close'], h:d_vol.mean()\n",
    "    tEvents,sPos,sNeg=[],0,0\n",
    "    diff=gRaw.diff()\n",
    "    h = float(h)\n",
    "    for i in diff.index[1:]:\n",
    "        sPos,sNeg=float(max(0,sPos+diff.loc[i])),float(min(0,sNeg+diff.loc[i]))\n",
    "        if sNeg<-h:\n",
    "            sNeg=0;tEvents.append(i)\n",
    "        elif sPos>h:\n",
    "            sPos=0;tEvents.append(i)\n",
    "    return pd.DatetimeIndex(tEvents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-04 10:01:00', '2016-01-04 10:04:00',\n",
       "               '2016-01-04 10:05:00', '2016-01-04 10:06:00',\n",
       "               '2016-01-04 10:07:00', '2016-01-04 10:09:00',\n",
       "               '2016-01-04 10:11:00', '2016-01-04 10:16:00',\n",
       "               '2016-01-04 10:18:00', '2016-01-04 10:19:00',\n",
       "               ...\n",
       "               '2016-01-13 10:15:00', '2016-01-13 10:16:00',\n",
       "               '2016-01-13 10:20:00', '2016-01-13 10:21:00',\n",
       "               '2016-01-13 10:22:00', '2016-01-13 10:23:00',\n",
       "               '2016-01-13 10:24:00', '2016-01-13 10:25:00',\n",
       "               '2016-01-13 10:26:00', '2016-01-13 10:27:00'],\n",
       "              dtype='datetime64[ns]', length=1664, freq=None)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tEvents = getTEvents(test_data['Close'], parkinson_vol.mean())\n",
    "tEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Tripple Barrier Labeling\n",
    "def applyPtSlOnT1(close,events,ptSl,molecule):\n",
    "    \n",
    "    '''\n",
    "    Tripple-barrier labeling method\n",
    "    ` Apply stop loss/profit taking, if it takes place before t1 (end of event)\n",
    "\n",
    "    Input: \n",
    "    ` events: \n",
    "      — t1: the timestamp of vertical barrier\n",
    "      — trgt: the unit width of the horizontal barriers, expressed in terms of absolute returns\n",
    "    ` ptsl: a list of two non-negative float values\n",
    "      - ptsl[0]: the factor multiplies trgt to set the width of the upper barrier\n",
    "      - ptsl[1]: the factor that multiplies trgt to set the width of the lower barrier\n",
    "    ` molecule: a list with the subset of event indices \n",
    "\n",
    "    Output: a Dataframe containing the timestamps at which each barrier was touched, [pt, s1, t1]\n",
    "    ` 0 (inactive barrier) or 1 (active barrier)\n",
    "\n",
    "    '''\n",
    "    #events_=events.loc[molecule]\n",
    "    events_=events\n",
    "    out=events_[['t1']].copy(deep=True)\n",
    "    if ptSl[0]>0:pt=ptSl[0]*events_['trgt']\n",
    "    else:pt=pd.Series(index=events.index) # NaNs\n",
    "    if ptSl[1]>0:sl=-ptSl[1]*events_['trgt']\n",
    "    else:sl=pd.Series(index=events.index) # NaNs\n",
    "    for loc,t1 in events_['t1'].fillna(close.index[-1]).iteritems():\n",
    "        df0=close[loc:t1] # path prices\n",
    "        df0=(df0/close[loc]-1)*events_.at[loc,'side'] # path returns\n",
    "        out.loc[loc,'sl']=df0[df0<sl[loc]].index.min() # earliest stop loss.\n",
    "        out.loc[loc,'pt']=df0[df0>pt[loc]].index.min() # earliest profit taking.\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.4.1 - mpPandasObj\n",
    "def linParts(numAtoms,numThreads):\n",
    "    # partition of atoms with a single loop\n",
    "    parts=np.linspace(0,numAtoms,min(numThreads,numAtoms)+1)\n",
    "    parts=np.ceil(parts).astype(int)\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.4.1 - mpPandasObj\n",
    "def nestedParts(numAtoms,numThreads,upperTriang=False):\n",
    "    # partition of atoms with an inner loop\n",
    "    parts,numThreads_=[0],min(numThreads,numAtoms)\n",
    "    for num in range(numThreads_):\n",
    "        part=1+4*(parts[-1]**2+parts[-1]+numAtoms*(numAtoms+1.)/numThreads_)\n",
    "        part=(-1+part**.5)/2.\n",
    "        parts.append(part)\n",
    "    parts=np.round(parts).astype(int)\n",
    "    if upperTriang: # the first rows are heaviest\n",
    "        parts=np.cumsum(np.diff(parts)[::-1])\n",
    "        parts=np.append(np.array([0]),parts)\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.8 - mpPandasObj\n",
    "def processJobs_(jobs):\n",
    "    # Run jobs sequentially, for debugging\n",
    "    out=[]\n",
    "    for job in jobs:\n",
    "        out_=expandCall(job)\n",
    "        out.append(out_)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20.10\n",
    "def expandCall(kargs):\n",
    "    # Expand the arguments of a callback function, kargs['func']\n",
    "    func=kargs['func']\n",
    "    del kargs['func']\n",
    "    out=func(**kargs)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Multiprocessing Obj\n",
    "def mpPandasObj(func,pdObj,numThreads=24,mpBatches=1,linMols=True,**kargs):\n",
    "    '''\n",
    "    Parallelize jobs, return a dataframe or series\n",
    "    + func: function to be parallelized. Returns a DataFrame\n",
    "    + pdObj[0]: Name of argument used to pass the molecule\n",
    "    + pdObj[1]: List of atoms that will be grouped into molecules\n",
    "    + kwds: any other argument needed by func\n",
    "    \n",
    "    Example: df1=mpPandasObj(func,('molecule',df0.index),24,**kwds)\n",
    "    '''\n",
    "    import pandas as pd\n",
    "    #if linMols:parts=linParts(len(argList[1]),numThreads*mpBatches)\n",
    "    #else:parts=nestedParts(len(argList[1]),numThreads*mpBatches)\n",
    "    if linMols:parts=linParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    else:parts=nestedParts(len(pdObj[1]),numThreads*mpBatches)\n",
    "    \n",
    "    jobs=[]\n",
    "    for i in range(1,len(parts)):\n",
    "        job={pdObj[0]:pdObj[1][parts[i-1]:parts[i]],'func':func}\n",
    "        job.update(kargs)\n",
    "        jobs.append(job)\n",
    "    if numThreads==1:out=processJobs_(jobs)\n",
    "    else: out=processJobs(jobs,numThreads=numThreads)\n",
    "    if isinstance(out[0],pd.DataFrame):df0=pd.DataFrame()\n",
    "    elif isinstance(out[0],pd.Series):df0=pd.Series()\n",
    "    else:return out\n",
    "    for i in out:df0=df0.append(i)\n",
    "    df0=df0.sort_index()\n",
    "    return df0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Get the First Time of Touch\n",
    "def getEvents(close,tEvents,ptSl,trgt,minRet,numThreads,t1=False,side=None):\n",
    "    '''\n",
    "    Getting the time of first touch\n",
    "     \n",
    "    Input:\n",
    "    ` tEvents: the pandas timeindex containing the timestamps that will seed every triple barrier \n",
    "      - the timestamps selected by the sampling procedures \n",
    "    ` minRet: the minimum target return required for running a triple barrier search\n",
    "    ` numThreads: the number of threads concurrently used by the function  \n",
    "\n",
    "    Output: \n",
    "    ` events: a Dataframe\n",
    "      - events.index: event's starttime\n",
    "      - events['t1']: event's endtime\n",
    "      - events['trgt']: event's target\n",
    "      - events['side'] (optional): the algo's position side\n",
    "    '''\n",
    "    #1) get target\n",
    "    trgt=trgt.loc[tEvents]\n",
    "    trgt=trgt[trgt>minRet] # minRet\n",
    "    #2) get t1 (max holding period)\n",
    "    if t1 is False:t1=pd.Series(pd.NaT,index=tEvents)\n",
    "    #3) form events object, apply stop loss on t1\n",
    "    if side is None:side_,ptSl_=pd.Series(1.,index=trgt.index),[ptSl[0],ptSl[0]]\n",
    "    else:side_,ptSl_=side.loc[trgt.index],ptSl[:2]\n",
    "    events=pd.concat({'t1':t1,'trgt':trgt,'side':side_}, axis=1).droplevel(1, axis=1).dropna(subset=['trgt'])\n",
    "    df0=mpPandasObj(func=applyPtSlOnT1,pdObj=('molecule',events.index), numThreads=numThreads,close=close,events=events,ptSl=ptSl_)\n",
    "    events['t1']=df0.dropna(how='all').min(axis=1) # pd.min ignores nan\n",
    "    if side is None:events=events.drop('side',axis=1)\n",
    "    return events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2016-01-04 10:01:00', '2016-01-04 10:04:00',\n",
       "               '2016-01-04 10:05:00', '2016-01-04 10:06:00',\n",
       "               '2016-01-04 10:07:00', '2016-01-04 10:09:00',\n",
       "               '2016-01-04 10:11:00', '2016-01-04 10:16:00',\n",
       "               '2016-01-04 10:18:00', '2016-01-04 10:19:00',\n",
       "               ...\n",
       "               '2016-01-13 10:15:00', '2016-01-13 10:16:00',\n",
       "               '2016-01-13 10:20:00', '2016-01-13 10:21:00',\n",
       "               '2016-01-13 10:22:00', '2016-01-13 10:23:00',\n",
       "               '2016-01-13 10:24:00', '2016-01-13 10:25:00',\n",
       "               '2016-01-13 10:26:00', '2016-01-13 10:27:00'],\n",
       "              dtype='datetime64[ns]', length=1664, freq=None)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tEvents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vertical Barrier\n",
    "def addVerticalBarrier(close, events, numDays=1):\n",
    "    t1=close.index.searchsorted(events+pd.Timedelta(days=numDays))\n",
    "    t1=t1[t1<close.shape[0]]\n",
    "    t1=pd.Series(close.index[t1],index=events[:t1.shape[0]]) # NaNs at end\n",
    "    return t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-01-04 10:01:00   2016-01-05 10:01:00\n",
       "2016-01-04 10:04:00   2016-01-05 10:04:00\n",
       "2016-01-04 10:05:00   2016-01-05 10:05:00\n",
       "2016-01-04 10:06:00   2016-01-05 10:06:00\n",
       "2016-01-04 10:07:00   2016-01-05 10:07:00\n",
       "                              ...        \n",
       "2016-01-12 10:19:00   2016-01-13 10:20:00\n",
       "2016-01-12 10:20:00   2016-01-13 10:20:00\n",
       "2016-01-12 10:22:00   2016-01-13 10:22:00\n",
       "2016-01-12 10:26:00   2016-01-13 10:26:00\n",
       "2016-01-12 10:27:00   2016-01-13 10:27:00\n",
       "Name: Date-Time, Length: 1449, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = addVerticalBarrier(test_data['Close'], tEvents, 1)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     t1      trgt\n",
      "2016-01-04 14:42:00 2016-01-05 11:30:00  0.012681\n",
      "2016-01-04 14:43:00 2016-01-05 12:05:00  0.012890\n",
      "2016-01-04 14:44:00 2016-01-05 12:05:00  0.012894\n",
      "2016-01-04 14:45:00 2016-01-05 12:05:00  0.012896\n",
      "2016-01-04 14:46:00 2016-01-05 12:08:00  0.012899\n",
      "2016-01-04 14:47:00 2016-01-05 12:05:00  0.012900\n",
      "2016-01-04 14:48:00 2016-01-05 12:05:00  0.012902\n",
      "2016-01-04 14:49:00 2016-01-05 12:05:00  0.012903\n",
      "2016-01-04 14:50:00 2016-01-05 12:05:00  0.012904\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cprint.cprint.cprint at 0x26f522be5d0>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create target series\n",
    "ptsl = [1,1]\n",
    "target=parkinson_vol\n",
    "# select minRet\n",
    "minRet = 0.01\n",
    "\n",
    "# Run in single-threaded mode on Windows\n",
    "import platform\n",
    "if platform.system() == \"Windows\":\n",
    "    cpus = 1\n",
    "else:\n",
    "    cpus = cpu_count() - 1\n",
    "    \n",
    "events = getEvents(test_data['Close'],tEvents,ptsl,target,minRet,cpus,t1=t1)\n",
    "\n",
    "# 최종적인 Tripple Barrier Output\n",
    "cprint(events) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
